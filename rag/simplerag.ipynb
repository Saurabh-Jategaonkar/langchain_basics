{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.\\n\\nFive score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to end the long night of their captivity.\\n\\nBut one hundred years later, the Negro still is not free. One hundred years later, the life of the Negro is still sadly crippled by the manacles of segregation and the chains of discrimination. One hundred years later, the Negro lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the Negro is still languished in the corners of American society and finds himself an exile in his own land. And so we\\'ve come here today to dramatize a shameful condition.\\n\\nIn a sense we\\'ve come to our nation\\'s capital to cash a check. When the architects of our republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promissory note to which every American was to fall heir. This note was a promise that all men, yes, black men as well as white men, would be guaranteed the \"unalienable Rights\" of \"Life, Liberty and the pursuit of Happiness.\" It is obvious today that America has defaulted on this promissory note, insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given the Negro people a bad check, a check which has come back marked \"insufficient funds.\"', metadata={'source': 'speech.txt'})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader=TextLoader(\"speech.txt\")\n",
    "text_documents=loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Web based loader\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "## load chunk and index the content of the html page\n",
    "\n",
    "loader=WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                         class_=(\"post-title\", \"post-content\", \"post-header\")\n",
    "                     )),)\n",
    "\n",
    "text_documents=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "could not convert string to float: '0.00-51177066' : FloatObject (b'0.00-51177066') invalid; use 0.0 instead\n",
      "could not convert string to float: '0.00-60790265' : FloatObject (b'0.00-60790265') invalid; use 0.0 instead\n",
      "could not convert string to float: '0.00-56221883' : FloatObject (b'0.00-56221883') invalid; use 0.0 instead\n"
     ]
    }
   ],
   "source": [
    "## PDF Loader\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('sample_pdf.pdf')\n",
    "\n",
    "text_documents=loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\nJunyuan Xie JXIE@CS.WASHINGTON .EDU\\nUniversity of Washington\\nRoss Girshick RBG@FB.COM\\nFacebook AI Research (FAIR)\\nAli Farhadi ALI@CS.WASHINGTON .EDU\\nUniversity of Washington\\nAbstract\\nClustering is central to many data-driven appli-\\ncation domains and has been studied extensively\\nin terms of distance functions and grouping al-\\ngorithms. Relatively little work has focused on\\nlearning representations for clustering. In this\\npaper, we propose Deep Embedded Clustering\\n(DEC), a method that simultaneously learns fea-\\nture representations and cluster assignments us-\\ning deep neural networks. DEC learns a map-\\nping from the data space to a lower-dimensional\\nfeature space in which it iteratively optimizes a\\nclustering objective. Our experimental evalua-\\ntions on image and text corpora show signiﬁcant\\nimprovement over state-of-the-art methods.\\n1. Introduction\\nClustering, an essential data analysis and visualization\\ntool, has been studied extensively in unsupervised machine\\nlearning from different perspectives: What deﬁnes a clus-\\nter? What is the right distance metric? How to efﬁciently\\ngroup instances into clusters? How to validate clusters?\\nAnd so on. Numerous different distance functions and em-\\nbedding methods have been explored in the literature. Rel-\\natively little work has focused on the unsupervised learning\\nof the feature space in which to perform clustering.\\nA notion of distance ordissimilarity is central to data clus-\\ntering algorithms. Distance, in turn, relies on represent-\\ning the data in a feature space. The k-means cluster-\\ning algorithm (MacQueen et al., 1967), for example, uses\\nthe Euclidean distance between points in a given feature\\nspace, which for images might be raw pixels or gradient-\\nProceedings of the 33rdInternational Conference on Machine\\nLearning , New York, NY , USA, 2016. JMLR: W&CP volume\\n48. Copyright 2016 by the author(s).orientation histograms. The choice of feature space is cus-\\ntomarily left as an application-speciﬁc detail for the end-\\nuser to determine. Yet it is clear that the choice of feature\\nspace is crucial; for all but the simplest image datasets,\\nclustering with Euclidean distance on raw pixels is com-\\npletely ineffective. In this paper, we revisit cluster analysis\\nand ask: Can we use a data driven approach to solve for\\nthe feature space and cluster memberships jointly?\\nWe take inspiration from recent work on deep learning for\\ncomputer vision (Krizhevsky et al., 2012; Girshick et al.,\\n2014; Zeiler & Fergus, 2014; Long et al., 2014), where\\nclear gains on benchmark tasks have resulted from learn-\\ning better features. These improvements, however, were\\nobtained with supervised learning, whereas our goal is un-\\nsupervised data clustering. To this end, we deﬁne a pa-\\nrameterized non-linear mapping from the data space Xto\\na lower-dimensional feature space Z, where we optimize\\na clustering objective. Unlike previous work, which oper-\\nates on the data space or a shallow linear embedded space,\\nwe use stochastic gradient descent (SGD) via backpropaga-\\ntion on a clustering objective to learn the mapping, which\\nis parameterized by a deep neural network. We refer to\\nthis clustering algorithm as Deep Embedded Clustering , or\\nDEC.\\nOptimizing DEC is challenging. We want to simultane-\\nously solve for cluster assignment and the underlying fea-\\nture representation. However, unlike in supervised learn-\\ning, we cannot train our deep network with labeled data.\\nInstead we propose to iteratively reﬁne clusters with an\\nauxiliary target distribution derived from the current soft\\ncluster assignment. This process gradually improves the\\nclustering as well as the feature representation.\\nOur experiments show signiﬁcant improvements over state-\\nof-the-art clustering methods in terms of both accuracy and\\nrunning time on image and textual datasets. We evaluate\\nDEC on MNIST (LeCun et al., 1998), STL (Coates et al.,arXiv:1511.06335v2  [cs.LG]  24 May 2016', metadata={'source': 'sample_pdf.pdf', 'page': 0}),\n",
       " Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\n2011), and REUTERS (Lewis et al., 2004), comparing it\\nwith standard and state-of-the-art clustering methods (Nie\\net al., 2011; Yang et al., 2010). In addition, our experiments\\nshow that DEC is signiﬁcantly less sensitive to the choice\\nof hyperparameters compared to state-of-the-art methods.\\nThis robustness is an important property of our clustering\\nalgorithm since, when applied to real data, supervision is\\nnot available for hyperparameter cross-validation.\\nOur contributions are: (a) joint optimization of deep em-\\nbedding and clustering; (b) a novel iterative reﬁnement\\nvia soft assignment; and (c) state-of-the-art clustering re-\\nsults in terms of clustering accuracy and speed. Our Caffe-\\nbased (Jia et al., 2014) implementation of DEC is available\\nathttps://github.com/piiswrong/dec .\\n2. Related work\\nClustering has been extensively studied in machine learn-\\ning in terms of feature selection (Boutsidis et al., 2009; Liu\\n& Yu, 2005; Alelyani et al., 2013), distance functions (Xing\\net al., 2002; Xiang et al., 2008), grouping methods (Mac-\\nQueen et al., 1967; V on Luxburg, 2007; Li et al., 2004),\\nand cluster validation (Halkidi et al., 2001). Space does\\nnot allow for a comprehensive literature study and we refer\\nreaders to (Aggarwal & Reddy, 2013) for a survey.\\nOne branch of popular methods for clustering is k-\\nmeans (MacQueen et al., 1967) and Gaussian Mixture\\nModels (GMM) (Bishop, 2006). These methods are fast\\nand applicable to a wide range of problems. However, their\\ndistance metrics are limited to the original data space and\\nthey tend to be ineffective when input dimensionality is\\nhigh (Steinbach et al., 2004).\\nSeveral variants of k-means have been proposed to address\\nissues with higher-dimensional input spaces. De la Torre &\\nKanade (2006); Ye et al. (2008) perform joint dimension-\\nality reduction and clustering by ﬁrst clustering the data\\nwithk-means and then projecting the data into a lower di-\\nmensions where the inter-cluster variance is maximized.\\nThis process is repeated in EM-style iterations until conver-\\ngence. However, this framework is limited to linear embed-\\nding; our method employs deep neural networks to perform\\nnon-linear embedding that is necessary for more complex\\ndata.\\nSpectral clustering and its variants have gained popular-\\nity recently (V on Luxburg, 2007). They allow more ﬂex-\\nible distance metrics and generally perform better than k-\\nmeans. Combining spectral clustering and embedding has\\nbeen explored in Yang et al. (2010); Nie et al. (2011). Tian\\net al. (2014) proposes an algorithm based on spectral clus-\\ntering, but replaces eigenvalue decomposition with deep\\nautoencoder, which improves performance but further in-\\ncreases memory consumption.Most spectral clustering algorithms need to compute the\\nfull graph Laplacian matrix and therefore have quadratic\\nor super quadratic complexities in the number of data\\npoints. This means they need specialized machines with\\nlarge memory for any dataset larger than a few tens of\\nthousands of points. In order to scale spectral clustering\\nto large datasets, approximate algorithms were invented to\\ntrade off performance for speed (Yan et al., 2009). Our\\nmethod, however, is linear in the number of data points and\\nscales gracefully to large datasets.\\nMinimizing the Kullback-Leibler (KL) divergence be-\\ntween a data distribution and an embedded distribution has\\nbeen used for data visualization and dimensionality reduc-\\ntion (van der Maaten & Hinton, 2008). T-SNE, for instance,\\nis a non-parametric algorithm in this school and a paramet-\\nric variant of t-SNE (van der Maaten, 2009) uses deep neu-\\nral network to parametrize the embedding. The complexity\\nof t-SNE is O(n2), wherenis the number of data points,\\nbut it can be approximated in O(nlogn)(van Der Maaten,\\n2014).\\nWe take inspiration from parametric t-SNE. Instead of min-\\nimizing KL divergence to produce an embedding that is\\nfaithful to distances in the original data space, we deﬁne\\na centroid-based probability distribution and minimize its\\nKL divergence to an auxiliary target distribution to simul-\\ntaneously improve clustering assignment and feature repre-\\nsentation. A centroid-based method also has the beneﬁt of\\nreducing complexity to O(nk), wherekis the number of\\ncentroids.\\n3. Deep embedded clustering\\nConsider the problem of clustering a set of npoints{xi∈\\nX}n\\ni=1intokclusters, each represented by a centroid\\nµj,j= 1,...,k . Instead of clustering directly in the data\\nspaceX, we propose to ﬁrst transform the data with a non-\\nlinear mapping fθ:X→Z, whereθare learnable pa-\\nrameters and Zis the latent feature space . The dimen-\\nsionality of Zis typically much smaller than Xin order\\nto avoid the “curse of dimensionality” (Bellman, 1961). To\\nparametrize fθ, deep neural networks (DNNs) are a natu-\\nral choice due to their theoretical function approximation\\nproperties (Hornik, 1991) and their demonstrated feature\\nlearning capabilities (Bengio et al., 2013).\\nThe proposed algorithm (DEC) clusters data by simultane-\\nously learning a set of kcluster centers{µj∈Z}k\\nj=1in the\\nfeature space Zand the parameters θof the DNN that maps\\ndata points into Z. DEC has two phases: (1) parameter ini-\\ntialization with a deep autoencoder (Vincent et al., 2010)\\nand (2) parameter optimization (i.e., clustering), where we\\niterate between computing an auxiliary target distribution\\nand minimizing the Kullback–Leibler (KL) divergence to', metadata={'source': 'sample_pdf.pdf', 'page': 1}),\n",
       " Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\nit. We start by describing phase (2) parameter optimiza-\\ntion/clustering, given an initial estimate of θand{µj}k\\nj=1.\\n3.1. Clustering with KL divergence\\nGiven an initial estimate of the non-linear mapping fθand\\nthe initial cluster centroids {µj}k\\nj=1, we propose to im-\\nprove the clustering using an unsupervised algorithm that\\nalternates between two steps. In the ﬁrst step, we com-\\npute a soft assignment between the embedded points and\\nthe cluster centroids. In the second step, we update the\\ndeep mapping fθand reﬁne the cluster centroids by learn-\\ning from current high conﬁdence assignments using an aux-\\niliary target distribution. This process is repeated until a\\nconvergence criterion is met.\\n3.1.1. S OFT ASSIGNMENT\\nFollowing van der Maaten & Hinton (2008) we use the Stu-\\ndent’st-distribution as a kernel to measure the similarity\\nbetween embedded point ziand centroid µj:\\nqij=(1 +∥zi−µj∥2/α)−α+1\\n2\\n∑\\nj′(1 +∥zi−µj′∥2/α)−α+1\\n2, (1)\\nwherezi=fθ(xi)∈Zcorresponds to xi∈Xafter em-\\nbedding,αare the degrees of freedom of the Student’s t-\\ndistribution and qijcan be interpreted as the probability\\nof assigning sample ito clusterj(i.e., a soft assignment).\\nSince we cannot cross-validate αon a validation set in the\\nunsupervised setting, and learning it is superﬂuous (van der\\nMaaten, 2009), we let α= 1for all experiments.\\n3.1.2. KL DIVERGENCE MINIMIZATION\\nWe propose to iteratively reﬁne the clusters by learning\\nfrom their high conﬁdence assignments with the help of\\nan auxiliary target distribution. Speciﬁcally, our model is\\ntrained by matching the soft assignment to the target distri-\\nbution. To this end, we deﬁne our objective as a KL diver-\\ngence loss between the soft assignments qiand the auxil-\\niary distribution pias follows:\\nL= KL(P∥Q) =∑\\ni∑\\njpijlogpij\\nqij. (2)\\nThe choice of target distributions Pis crucial for DEC’s\\nperformance. A naive approach would be setting each pito\\na delta distribution (to the nearest centroid) for data points\\nabove a conﬁdence threshold and ignore the rest. How-\\never, because qiare soft assignments, it is more natural\\nand ﬂexible to use softer probabilistic targets. Speciﬁcally,\\nwe would like our target distribution to have the following\\nproperties: (1) strengthen predictions (i.e., improve clus-\\nter purity), (2) put more emphasis on data points assigned\\nwith high conﬁdence, and (3) normalize loss contributionof each centroid to prevent large clusters from distorting\\nthe hidden feature space.\\nIn our experiments, we compute piby ﬁrst raising qito\\nthe second power and then normalizing by frequency per\\ncluster:\\npij=q2\\nij/fj∑\\nj′q2\\nij′/fj′, (3)\\nwherefj=∑\\niqijare soft cluster frequencies. Please\\nrefer to section 5.1 for discussions on empirical properties\\nofLandP.\\nOur training strategy can be seen as a form of self-\\ntraining (Nigam & Ghani, 2000). As in self-training, we\\ntake an initial classiﬁer and an unlabeled dataset, then la-\\nbel the dataset with the classiﬁer in order to train on its\\nown high conﬁdence predictions. Indeed, in experiments\\nwe observe that DEC improves upon the initial estimate\\nin each iteration by learning from high conﬁdence predic-\\ntions, which in turn helps to improve low conﬁdence ones.\\n3.1.3. O PTIMIZATION\\nWe jointly optimize the cluster centers {µj}and DNN pa-\\nrametersθusing Stochastic Gradient Descent (SGD) with\\nmomentum. The gradients of Lwith respect to feature-\\nspace embedding of each data point ziand each cluster\\ncentroidµjare computed as:\\n∂L\\n∂zi=α+ 1\\nα∑\\nj(1 +∥zi−µj∥2\\nα)−1(4)\\n×(pij−qij)(zi−µj),\\n∂L\\n∂µj=−α+ 1\\nα∑\\ni(1 +∥zi−µj∥2\\nα)−1(5)\\n×(pij−qij)(zi−µj).\\nThe gradients ∂L/∂ziare then passed down to the DNN\\nand used in standard backpropagation to compute the\\nDNN’s parameter gradient ∂L/∂θ . For the purpose of dis-\\ncovering cluster assignments, we stop our procedure when\\nless than tol%of points change cluster assignment between\\ntwo consecutive iterations.\\n3.2. Parameter initialization\\nThus far we have discussed how DEC proceeds given ini-\\ntial estimates of the DNN parameters θand the cluster cen-\\ntroids{µj}. Now we discuss how the parameters and cen-\\ntroids are initialized.\\nWe initialize DEC with a stacked autoencoder (SAE) be-\\ncause recent research has shown that they consistently pro-\\nduce semantically meaningful and well-separated represen-\\ntations on real-world datasets (Vincent et al., 2010; Hin-\\nton & Salakhutdinov, 2006; Le, 2013). Thus the unsuper-', metadata={'source': 'sample_pdf.pdf', 'page': 2}),\n",
       " Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\nTable 1. Dataset statistics.\\nDataset # Points # classes Dimension % of largest class\\nMNIST (LeCun et al., 1998) 70000 10 784 11%\\nSTL-10 (Coates et al., 2011) 13000 10 1428 10%\\nREUTERS-10K 10000 4 2000 43%\\nREUTERS (Lewis et al., 2004) 685071 4 2000 43%\\nP\\nQ\\nL = KL(P||Q) encoder decoder \\nDEC \\ninput reconstruction \\nfeature \\nFigure 1. Network structure\\nvised representation learned by SAE naturally facilitates\\nthe learning of clustering representations with DEC.\\nWe initialize the SAE network layer by layer with each\\nlayer being a denoising autoencoder trained to reconstruct\\nthe previous layer’s output after random corruption (Vin-\\ncent et al., 2010). A denoising autoencoder is a two layer\\nneural network deﬁned as:\\n˜x∼Dropout (x) (6)\\nh=g1(W1˜x+b1) (7)\\n˜h∼Dropout (h) (8)\\ny=g2(W2˜h+b2) (9)\\nwhere Dropout (·)(Srivastava et al., 2014) is a stochastic\\nmapping that randomly sets a portion of its input dimen-\\nsions to 0,g1andg2are activation functions for encoding\\nand decoding layer respectively, and θ={W1,b1,W2,b2}\\nare model parameters. Training is performed by minimiz-\\ning the least-squares loss ∥x−y∥2\\n2. After training of one\\nlayer, we use its output has the input to train the next\\nlayer. We use rectiﬁed linear units (ReLUs) (Nair & Hin-\\nton, 2010) in all encoder/decoder pairs, except for g2of the\\nﬁrst pair (it needs to reconstruct input data that may have\\npositive and negative values, such as zero-mean images)\\nandg1of the lastpair (so the ﬁnal data embedding retains\\nfull information (Vincent et al., 2010)).\\nAfter greedy layer-wise training, we concatenate all en-\\ncoder layers followed by all decoder layers, in reverse\\nlayer-wise training order, to form a deep autoencoder and\\nthen ﬁnetune it to minimize reconstruction loss. The ﬁnal\\nresult is a multilayer deep autoencoder with a bottleneck\\ncoding layer in the middle. We then discard the decoderlayers and use the encoder layers as our initial mapping be-\\ntween the data space and the feature space, as shown in\\nFig. 1.\\nTo initialize the cluster centers, we pass the data through\\nthe initialized DNN to get embedded data points and then\\nperform standard k-means clustering in the feature space Z\\nto obtainkinitial centroids{µj}k\\nj=1.\\n4. Experiments\\n4.1. Datasets\\nWe evaluate the proposed method (DEC) on one text\\ndataset and two image datasets and compare it against other\\nalgorithms including k-means, LDGMI (Yang et al., 2010),\\nand SEC (Nie et al., 2011). LDGMI and SEC are spec-\\ntral clustering based algorithms that use a Laplacian matrix\\nand various transformations to improve clustering perfor-\\nmance. Empirical evidence reported in Yang et al. (2010);\\nNie et al. (2011) shows that LDMGI and SEC outperform\\ntraditional spectral clustering methods on a wide range of\\ndatasets. We show qualitative and quantitative results that\\ndemonstrate the beneﬁt of DEC compared to LDGMI and\\nSEC.\\nIn order to study the performance and generality of dif-\\nferent algorithms, we perform experiment on two image\\ndatasets and one text data set:\\n•MNIST : The MNIST dataset consists of 70000 hand-\\nwritten digits of 28-by-28 pixel size. The digits are\\ncentered and size-normalized (LeCun et al., 1998).\\n•STL-10 : A dataset of 96-by-96 color images. There\\nare 10 classes with 1300 examples each. It also con-\\ntains 100000 unlabeled images of the same resolu-\\ntion (Coates et al., 2011). We also used the unlabeled\\nset when training our autoencoders. Similar to Doer-\\nsch et al. (2012), we concatenated HOG feature and a\\n8-by-8 color map to use as input to all algorithms.\\n•REUTERS : Reuters contains about 810000 English\\nnews stories labeled with a category tree (Lewis et al.,\\n2004). We used the four root categories: corpo-\\nrate/industrial, government/social, markets, and eco-\\nnomics as labels and further pruned all documents that\\nare labeled by multiple root categories to get 685071', metadata={'source': 'sample_pdf.pdf', 'page': 3}),\n",
       " Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\n24680.50.550.60.650.70.750.80.850.9Accuracy\\nParameter Index\\nMNIST  DEC DEC w/o backprop Kmeans LDGMI SEC\\n24680.20.250.30.350.4Accuracy\\nParameter Index\\nSTL24680.350.40.450.50.550.60.650.70.75Accuracy\\nParameter Index\\nREUTERS−10K24680.50.550.60.650.70.750.80.85Accuracy\\nParameter Index\\nREUTERS\\nFigure 2. Clustering accuracy for different hyperparameter choices for each algorithm. DEC outperforms other methods and is more\\nrobust to hyperparameter changes compared to either LDGMI or SEC. Robustness is important because cross-validation is not possible\\nin real-world applications of cluster analysis. This ﬁgure is best viewed in color.\\nTable 2. Comparison of clustering accuracy (Eq. 10) on four datasets.\\nMethod MNIST STL-HOG REUTERS-10k REUTERS\\nk-means 53.49% 28.39% 52.42% 53.29%\\nLDMGI 84.09% 33.08% 43.84% N/A\\nSEC 80.37% 30.75% 60.08% N/A\\nDEC w/o backprop 79.82% 34.06% 70.05% 69.62%\\nDEC (ours) 84.30% 35.90% 72.17% 75.63%\\narticles. We then computed tf-idf features on the 2000\\nmost frequently occurring word stems. Since some\\nalgorithms do not scale to the full Reuters dataset,\\nwe also sampled a random subset of 10000 examples,\\nwhich we call REUTERS-10k, for comparison pur-\\nposes.\\nA summary of dataset statistics is shown in Table 1. For\\nall algorithms, we normalize all datasets so that1\\nd∥xi∥2\\n2is\\napproximately 1, where dis the dimensionality of the data\\nspace pointxi∈X.\\n4.2. Evaluation Metric\\nWe use the standard unsupervised evaluation metric and\\nprotocols for evaluations and comparisons to other algo-\\nrithms (Yang et al., 2010). For all algorithms we set the\\nnumber of clusters to the number of ground-truth categories\\nand evaluate performance with unsupervised clustering ac-\\ncuracy ( ACC ):\\nACC = max\\nm∑n\\ni=11{li=m(ci)}\\nn, (10)\\nwhereliis the ground-truth label, ciis the cluster assign-\\nment produced by the algorithm, and mranges over all pos-\\nsible one-to-one mappings between clusters and labels.\\nIntuitively this metric takes a cluster assignment from an\\nunsupervised algorithm and a ground truth assignment and\\nthen ﬁnds the best matching between them. The best map-ping can be efﬁciently computed by the Hungarian algo-\\nrithm (Kuhn, 1955).\\n4.3. Implementation\\nDetermining hyperparameters by cross-validation on a vali-\\ndation set is not an option in unsupervised clustering. Thus\\nwe use commonly used parameters for DNNs and avoid\\ndataset speciﬁc tuning as much as possible. Speciﬁcally,\\ninspired by van der Maaten (2009), we set network dimen-\\nsions tod–500–500–2000–10 for all datasets, where dis\\nthe data-space dimension, which varies between datasets.\\nAll layers are densely (fully) connected.\\nDuring greedy layer-wise pretraining we initialize the\\nweights to random numbers drawn from a zero-mean Gaus-\\nsian distribution with a standard deviation of 0.01. Each\\nlayer is pretrained for 50000 iterations with a dropout rate\\nof20%. The entire deep autoencoder is further ﬁnetuned\\nfor 100000 iterations without dropout. For both layer-wise\\npretraining and end-to-end ﬁnetuning of the autoencoder\\nthe minibatch size is set to 256, starting learning rate is\\nset to 0.1, which is divided by 10 every 20000 iterations,\\nand weight decay is set to 0. All of the above param-\\neters are set to achieve a reasonably good reconstruction\\nloss and are held constant across all datasets. Dataset-\\nspeciﬁc settings of these parameters might improve perfor-\\nmance on each dataset, but we refrain from this type of\\nunrealistic parameter tuning. To initialize centroids, we\\nrunk-means with 20 restarts and select the best solution.', metadata={'source': 'sample_pdf.pdf', 'page': 4}),\n",
       " Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\n(a) MNIST\\n (b) STL-10\\nFigure 3. Each row contains the top 10 scoring elements from one cluster.\\nIn the KL divergence minimization phase, we train with\\na constant learning rate of 0.01. The convergence thresh-\\nold is set to tol= 0.1%. Our implementation is based\\non Python and Caffe (Jia et al., 2014) and is available at\\nhttps://github.com/piiswrong/dec .\\nFor all baseline algorithms, we perform 20 random restarts\\nwhen initializing centroids and pick the result with the\\nbest objective value. For a fair comparison with previ-\\nous work (Yang et al., 2010), we vary one hyperparameter\\nfor each algorithm over 9 possible choices and report the\\nbest accuracy in Table 2 and the range of accuracies in Fig.\\n2. For LDGMI and SEC, we use the same parameter and\\nrange as in their corresponding papers. For our proposed\\nalgorithm, we vary λ, the parameter that controls annealing\\nspeed, over 2i×10,i= 0,1,...,8. Sincek-means does not\\nhave tunable hyperparameters (aside from k), we simply\\nrun them 9 times. GMMs perform similarly to k-means so\\nwe only report k-means results. Traditional spectral clus-\\ntering performs worse than LDGMI and SEC so we only\\nreport the latter (Yang et al., 2010; Nie et al., 2011).\\n4.4. Experiment results\\nWe evaluate the performance of our algorithm both quan-\\ntitatively and qualitatively. In Table 2, we report the best\\nperformance, over 9 hyperparameter settings, of each al-\\ngorithm. Note that DEC outperforms all other methods,\\nsometimes with a signiﬁcant margin. To demonstrate the\\neffectiveness of end-to-end training, we also show the re-\\nsults from freezing the non-linear mapping fθduring clus-\\ntering. We ﬁnd that this ablation (“DEC w/o backprop”)\\ngenerally performs worse than DEC.In order to investigate the effect of hyperparameters, we\\nplot the accuracy of each method under all 9 settings (Fig.\\n2). We observe that DEC is more consistent across hyper-\\nparameter ranges compared to LDGMI and SEC. For DEC,\\nhyperparameter λ= 40 gives near optimal performance on\\nall dataset, whereas for other algorithms the optimal hyper-\\nparameter varies widely. Moreover, DEC can process the\\nentire REUTERS dataset in half an hour with GPU acceler-\\nation while the second best algorithms, LDGMI and SEC,\\nwould need months of computation time and terabytes of\\nmemory. We, indeed, could not run these methods on the\\nfull REUTERS dataset and report N/A in Table 2 (GPU\\nadaptation of these methods is non-trivial).\\nIn Fig. 3 we show 10 top scoring images from each clus-\\nter in MNIST and STL. Each row corresponds to a cluster\\nand images are sorted from left to right based on their dis-\\ntance to the cluster center. We observe that for MNIST,\\nDEC’s cluster assignment corresponds to natural clusters\\nvery well, with the exception of confusing 4 and 9, while\\nfor STL, DEC is mostly correct with airplanes, trucks and\\ncars, but spends part of its attention on poses instead of\\ncategories when it comes to animal classes.\\n5. Discussion\\n5.1. Assumptions and Objective\\nThe underlying assumption of DEC is that the initial clas-\\nsiﬁer’s high conﬁdence predictions are mostly correct. To\\nverify that this assumption holds for our task and that our\\nchoice ofPhas the desired properties, we plot the mag-\\nnitude of the gradient of Lwith respect to each embedded\\npoint,|∂L/∂zi|, against its soft assignment, qij, to a ran-', metadata={'source': 'sample_pdf.pdf', 'page': 5}),\n",
       " Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\n(a) Epoch 0\\n (b) Epoch 3\\n (c) Epoch 6\\n(d) Epoch 9\\n (e) Epoch 12\\n0 10 20 30\\n0.790.80.810.820.830.84AccuracyEpochs\\nk-means initialization (f) Accuracy vs. epochs\\nFigure 5. We visualize the latent representation as the KL divergence minimization phase proceeds on MNIST. Note the separation of\\nclusters from epoch 0 to epoch 12. We also plot the accuracy of DEC at different epochs, showing that KL divergence minimization\\nimproves clustering accuracy. This ﬁgure is best viewed in color.\\nTable 3. Comparison of clustering accuracy (Eq. 10) on autoencoder (AE) feature.\\nMethod MNIST STL-HOG REUTERS-10k REUTERS\\nAE+k-means 81.84% 33.92% 66.59% 71.97%\\nAE+LDMGI 83.98% 32.04% 42.92% N/A\\nAE+SEC 81.56% 32.29% 61.86% N/A\\nDEC (ours) 84.30% 35.90% 72.17% 75.63%\\nFigure 4. Gradient visualization at the start of KL divergence min-\\nimization. This plot shows the magnitude of the gradient of the\\nlossLvs. the cluster soft assignment probability qij. See text for\\ndiscussion.\\ndomly chosen MNIST cluster j(Fig. 4).\\nWe observe points that are closer to the cluster center (largeqij) contribute more to the gradient. We also show the raw\\nimages of 10 data points at each 10 percentile sorted by qij.\\nInstances with higher similarity are more canonical exam-\\nples of “5”. As conﬁdence decreases, instances become\\nmore ambiguous and eventually turn into a mislabeled “8”\\nsuggesting the soundness of our assumptions.\\n5.2. Contribution of Iterative Optimization\\nIn Fig. 5 we visualize the progression of the embedded rep-\\nresentation of a random subset of MNIST during training.\\nFor visualization we use t-SNE (van der Maaten & Hinton,\\n2008) applied to the embedded points zi. It is clear that\\nthe clusters are becoming increasingly well separated. Fig.\\n5 (f) shows how accuracy correspondingly improves over\\nSGD epochs.\\n5.3. Contribution of Autoencoder Initialization\\nTo better understand the contribution of each component,\\nwe show the performance of all algorithms with autoen-\\ncoder features in Table 3. We observe that SEC and LD-\\nMGI’s performance do not change signiﬁcantly with au-', metadata={'source': 'sample_pdf.pdf', 'page': 6}),\n",
       " Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\nTable 4. Clustering accuracy (Eq. 10) on imbalanced subsample of MNIST.XXXXXXXXXXMethodrmin0.1 0.3 0.5 0.7 0.9\\nk-means 47.14% 49.93% 53.65% 54.16% 54.39%\\nAE+k-means 66.82% 74.91% 77.93% 80.04% 81.31%\\nDEC 70.10% 80.92% 82.68% 84.69% 85.41%\\ntoencoder feature, while k-means improved but is still be-\\nlow DEC. This demonstrates the power of deep embedding\\nand the beneﬁt of ﬁne-tuning with the proposed KL diver-\\ngence objective.\\n5.4. Performance on Imbalanced Data\\nIn order to study the effect of imbalanced data, we sample\\nsubsets of MNIST with various retention rates. For mini-\\nmum retention rate rmin, data points of class 0 will be kept\\nwith probability rminand class 9 with probability 1, with\\nthe other classes linearly in between. As a result the largest\\ncluster will be 1/rmintimes as large as the smallest one.\\nFrom Table 4 we can see that DEC is fairly robust against\\ncluster size variation. We also observe that KL divergence\\nminimization (DEC) consistently improves clustering ac-\\ncuracy after autoencoder and k-means initialization (shown\\nas AE+k-means).\\n5.5. Number of Clusters\\n00.20.40.60.81\\n35791113151719Number\\t\\r \\xa0of\\t\\r \\xa0ClustersNMIGeneralizability\\nFigure 6. Selection of the centroid count, k. This is a plot of Nor-\\nmalized Mutual Information (NMI) and Generalizability vs. num-\\nber of clusters. Note that there is a sharp drop of generalizability\\nfrom 9 to 10 which means that 9 is the optimal number of clusters.\\nIndeed, we observe that 9 gives the highest NMI.\\nSo far we have assumed that the number of natural clusters\\nis given to simplify comparison between algorithms. How-\\never, in practice this quantity is often unknown. Therefore\\na method for determining the optimal number of clusters is\\nneeded. To this end, we deﬁne two metrics: (1) the standard\\nmetric, Normalized Mutual Information (NMI), for evalu-ating clustering results with different cluster number:\\nNMI (l,c) =I(l,c)\\n1\\n2[H(l) +H(c)],\\nwhereIis the mutual information metric and His entropy,\\nand (2) generalizability ( G) which is deﬁned as the ratio\\nbetween training and validation loss:\\nG=Ltrain\\nLvalidation.\\nGis small when training loss is lower than validation loss,\\nwhich indicate a high degree of overﬁtting.\\nFig. 6 shows a sharp drop in generalizability when cluster\\nnumber increases from 9 to 10, which suggests that 9 is the\\noptimal number of clusters. We indeed observe the highest\\nNMI score at 9, which demonstrates that generalizability is\\na good metric for selecting cluster number. NMI is highest\\nat 9 instead 10 because 9 and 4 are similar in writing and\\nDEC thinks that they should form a single cluster. This\\ncorresponds well with our qualitative results in Fig. 3.\\n6. Conclusion\\nThis paper presents Deep Embedded Clustering, or DEC—\\nan algorithm that clusters a set of data points in a jointly op-\\ntimized feature space. DEC works by iteratively optimiz-\\ning a KL divergence based clustering objective with a self-\\ntraining target distribution. Our method can be viewed as\\nan unsupervised extension of semisupervised self-training.\\nOur framework provide a way to learn a representation spe-\\ncialized for clustering without groundtruth cluster member-\\nship labels.\\nEmpirical studies demonstrate the strength of our proposed\\nalgorithm. DEC offers improved performance as well as\\nrobustness with respect to hyperparameter settings, which\\nis particularly important in unsupervised tasks since cross-\\nvalidation is not possible. DEC also has the virtue of linear\\ncomplexity in the number of data points which allows it to\\nscale to large datasets.\\n7. Acknowledgment\\nThis work is in part supported by ONR N00014-13-1-0720,\\nNSF IIS- 1338054, and Allen Distinguished Investigator\\nAward.', metadata={'source': 'sample_pdf.pdf', 'page': 7}),\n",
       " Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\nReferences\\nAggarwal, Charu C and Reddy, Chandan K. Data cluster-\\ning: algorithms and applications . CRC Press, 2013.\\nAlelyani, Salem, Tang, Jiliang, and Liu, Huan. Feature\\nselection for clustering: A review. Data Clustering: Al-\\ngorithms and Applications , 2013.\\nBellman, R. Adaptive Control Processes: A Guided Tour .\\nPrinceton University Press, Princeton, New Jersey, 1961.\\nBengio, Yoshua, Courville, Aaron, and Vincent, Pascal.\\nRepresentation learning: A review and new perspectives.\\n2013.\\nBishop, Christopher M. Pattern recognition and machine\\nlearning . springer New York, 2006.\\nBoutsidis, Christos, Drineas, Petros, and Mahoney,\\nMichael W. Unsupervised feature selection for the k-\\nmeans clustering problem. In NIPS , 2009.\\nCoates, Adam, Ng, Andrew Y , and Lee, Honglak. An\\nanalysis of single-layer networks in unsupervised feature\\nlearning. In International Conference on Artiﬁcial Intel-\\nligence and Statistics , pp. 215–223, 2011.\\nDe la Torre, Fernando and Kanade, Takeo. Discriminative\\ncluster analysis. In ICML , 2006.\\nDoersch, Carl, Singh, Saurabh, Gupta, Abhinav, Sivic,\\nJosef, and Efros, Alexei. What makes paris look like\\nparis? ACM Transactions on Graphics , 2012.\\nGirshick, Ross, Donahue, Jeff, Darrell, Trevor, and Malik,\\nJitendra. Rich feature hierarchies for accurate object de-\\ntection and semantic segmentation. In CVPR , 2014.\\nHalkidi, Maria, Batistakis, Yannis, and Vazirgiannis,\\nMichalis. On clustering validation techniques. Journal\\nof Intelligent Information Systems , 2001.\\nHinton, Geoffrey E and Salakhutdinov, Ruslan R. Reduc-\\ning the dimensionality of data with neural networks. Sci-\\nence, 313(5786):504–507, 2006.\\nHornik, Kurt. Approximation capabilities of multilayer\\nfeedforward networks. Neural networks , 4(2):251–257,\\n1991.\\nJia, Yangqing, Shelhamer, Evan, Donahue, Jeff, Karayev,\\nSergey, Long, Jonathan, Girshick, Ross, Guadarrama,\\nSergio, and Darrell, Trevor. Caffe: Convolutional ar-\\nchitecture for fast feature embedding. arXiv preprint\\narXiv:1408.5093 , 2014.\\nKrizhevsky, Alex, Sutskever, Ilya, and Hinton, Geoffrey E.\\nImagenet classiﬁcation with deep convolutional neural\\nnetworks. In NIPS , 2012.Kuhn, Harold W. The hungarian method for the assignment\\nproblem. Naval research logistics quarterly , 2(1-2):83–\\n97, 1955.\\nLe, Quoc V . Building high-level features using large scale\\nunsupervised learning. In Acoustics, Speech and Signal\\nProcessing (ICASSP), 2013 IEEE International Confer-\\nence on , pp. 8595–8598. IEEE, 2013.\\nLeCun, Yann, Bottou, L ´eon, Bengio, Yoshua, and Haffner,\\nPatrick. Gradient-based learning applied to document\\nrecognition. Proceedings of the IEEE , 86(11):2278–\\n2324, 1998.\\nLewis, David D, Yang, Yiming, Rose, Tony G, and Li, Fan.\\nRcv1: A new benchmark collection for text categoriza-\\ntion research. JMLR , 2004.\\nLi, Tao, Ma, Sheng, and Ogihara, Mitsunori. Entropy-\\nbased criterion in categorical clustering. In ICML , 2004.\\nLiu, Huan and Yu, Lei. Toward integrating feature selection\\nalgorithms for classiﬁcation and clustering. IEEE Trans-\\nactions on Knowledge and Data Engineering , 2005.\\nLong, Jonathan, Shelhamer, Evan, and Darrell, Trevor.\\nFully convolutional networks for semantic segmentation.\\narXiv preprint arXiv:1411.4038 , 2014.\\nMacQueen, James et al. Some methods for classiﬁcation\\nand analysis of multivariate observations. In Proceed-\\nings of the ﬁfth Berkeley symposium on mathematical\\nstatistics and probability , pp. 281–297, 1967.\\nNair, Vinod and Hinton, Geoffrey E. Rectiﬁed linear units\\nimprove restricted boltzmann machines. In ICML , 2010.\\nNie, Feiping, Zeng, Zinan, Tsang, Ivor W, Xu, Dong,\\nand Zhang, Changshui. Spectral embedded clustering:\\nA framework for in-sample and out-of-sample spectral\\nclustering. IEEE Transactions on Neural Networks ,\\n2011.\\nNigam, Kamal and Ghani, Rayid. Analyzing the effective-\\nness and applicability of co-training. In Proc. of the ninth\\ninternational conference on Information and knowledge\\nmanagement , 2000.\\nSrivastava, Nitish, Hinton, Geoffrey, Krizhevsky, Alex,\\nSutskever, Ilya, and Salakhutdinov, Ruslan. Dropout: A\\nsimple way to prevent neural networks from overﬁtting.\\nJMLR , 2014.\\nSteinbach, Michael, Ert ¨oz, Levent, and Kumar, Vipin. The\\nchallenges of clustering high dimensional data. In New\\nDirections in Statistical Physics , pp. 273–309. Springer,\\n2004.', metadata={'source': 'sample_pdf.pdf', 'page': 8}),\n",
       " Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\nTian, Fei, Gao, Bin, Cui, Qing, Chen, Enhong, and Liu,\\nTie-Yan. Learning deep representations for graph clus-\\ntering. In AAAI Conference on Artiﬁcial Intelligence ,\\n2014.\\nvan der Maaten, Laurens. Learning a parametric embed-\\nding by preserving local structure. In International Con-\\nference on Artiﬁcial Intelligence and Statistics , 2009.\\nvan Der Maaten, Laurens. Accelerating t-SNE using tree-\\nbased algorithms. JMLR , 2014.\\nvan der Maaten, Laurens and Hinton, Geoffrey. Visualizing\\ndata using t-SNE. JMLR , 2008.\\nVincent, Pascal, Larochelle, Hugo, Lajoie, Isabelle, Ben-\\ngio, Yoshua, and Manzagol, Pierre-Antoine. Stacked de-\\nnoising autoencoders: Learning useful representations in\\na deep network with a local denoising criterion. JMLR ,\\n2010.\\nV on Luxburg, Ulrike. A tutorial on spectral clustering.\\nStatistics and computing , 2007.\\nXiang, Shiming, Nie, Feiping, and Zhang, Changshui.\\nLearning a mahalanobis distance metric for data cluster-\\ning and classiﬁcation. Pattern Recognition , 2008.\\nXing, Eric P, Jordan, Michael I, Russell, Stuart, and Ng,\\nAndrew Y . Distance metric learning with application to\\nclustering with side-information. In NIPS , 2002.\\nYan, Donghui, Huang, Ling, and Jordan, Michael I. Fast\\napproximate spectral clustering. In ACM SIGKDD ,\\n2009.\\nYang, Yi, Xu, Dong, Nie, Feiping, Yan, Shuicheng, and\\nZhuang, Yueting. Image clustering using local discrim-\\ninant models and global integration. IEEE Transactions\\non Image Processing , 2010.\\nYe, Jieping, Zhao, Zheng, and Wu, Mingrui. Discrimina-\\ntive k-means for clustering. In NIPS , 2008.\\nZeiler, Matthew D and Fergus, Rob. Visualizing and un-\\nderstanding convolutional networks. In ECCV . 2014.', metadata={'source': 'sample_pdf.pdf', 'page': 9})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Unsupervised Deep Embedding for Clustering Analysis\\nJunyuan Xie JXIE@CS.WASHINGTON .EDU\\nUniversity of Washington\\nRoss Girshick RBG@FB.COM\\nFacebook AI Research (FAIR)\\nAli Farhadi ALI@CS.WASHINGTON .EDU\\nUniversity of Washington\\nAbstract\\nClustering is central to many data-driven appli-\\ncation domains and has been studied extensively\\nin terms of distance functions and grouping al-\\ngorithms. Relatively little work has focused on\\nlearning representations for clustering. In this\\npaper, we propose Deep Embedded Clustering\\n(DEC), a method that simultaneously learns fea-\\nture representations and cluster assignments us-\\ning deep neural networks. DEC learns a map-\\nping from the data space to a lower-dimensional\\nfeature space in which it iteratively optimizes a\\nclustering objective. Our experimental evalua-\\ntions on image and text corpora show signiﬁcant\\nimprovement over state-of-the-art methods.\\n1. Introduction\\nClustering, an essential data analysis and visualization', metadata={'source': 'sample_pdf.pdf', 'page': 0}),\n",
       " Document(page_content='tool, has been studied extensively in unsupervised machine\\nlearning from different perspectives: What deﬁnes a clus-\\nter? What is the right distance metric? How to efﬁciently\\ngroup instances into clusters? How to validate clusters?\\nAnd so on. Numerous different distance functions and em-\\nbedding methods have been explored in the literature. Rel-\\natively little work has focused on the unsupervised learning\\nof the feature space in which to perform clustering.\\nA notion of distance ordissimilarity is central to data clus-\\ntering algorithms. Distance, in turn, relies on represent-\\ning the data in a feature space. The k-means cluster-\\ning algorithm (MacQueen et al., 1967), for example, uses\\nthe Euclidean distance between points in a given feature\\nspace, which for images might be raw pixels or gradient-\\nProceedings of the 33rdInternational Conference on Machine\\nLearning , New York, NY , USA, 2016. JMLR: W&CP volume', metadata={'source': 'sample_pdf.pdf', 'page': 0}),\n",
       " Document(page_content='48. Copyright 2016 by the author(s).orientation histograms. The choice of feature space is cus-\\ntomarily left as an application-speciﬁc detail for the end-\\nuser to determine. Yet it is clear that the choice of feature\\nspace is crucial; for all but the simplest image datasets,\\nclustering with Euclidean distance on raw pixels is com-\\npletely ineffective. In this paper, we revisit cluster analysis\\nand ask: Can we use a data driven approach to solve for\\nthe feature space and cluster memberships jointly?\\nWe take inspiration from recent work on deep learning for\\ncomputer vision (Krizhevsky et al., 2012; Girshick et al.,\\n2014; Zeiler & Fergus, 2014; Long et al., 2014), where\\nclear gains on benchmark tasks have resulted from learn-\\ning better features. These improvements, however, were\\nobtained with supervised learning, whereas our goal is un-\\nsupervised data clustering. To this end, we deﬁne a pa-\\nrameterized non-linear mapping from the data space Xto', metadata={'source': 'sample_pdf.pdf', 'page': 0}),\n",
       " Document(page_content='a lower-dimensional feature space Z, where we optimize\\na clustering objective. Unlike previous work, which oper-\\nates on the data space or a shallow linear embedded space,\\nwe use stochastic gradient descent (SGD) via backpropaga-\\ntion on a clustering objective to learn the mapping, which\\nis parameterized by a deep neural network. We refer to\\nthis clustering algorithm as Deep Embedded Clustering , or\\nDEC.\\nOptimizing DEC is challenging. We want to simultane-\\nously solve for cluster assignment and the underlying fea-\\nture representation. However, unlike in supervised learn-\\ning, we cannot train our deep network with labeled data.\\nInstead we propose to iteratively reﬁne clusters with an\\nauxiliary target distribution derived from the current soft\\ncluster assignment. This process gradually improves the\\nclustering as well as the feature representation.\\nOur experiments show signiﬁcant improvements over state-\\nof-the-art clustering methods in terms of both accuracy and', metadata={'source': 'sample_pdf.pdf', 'page': 0}),\n",
       " Document(page_content='running time on image and textual datasets. We evaluate\\nDEC on MNIST (LeCun et al., 1998), STL (Coates et al.,arXiv:1511.06335v2  [cs.LG]  24 May 2016', metadata={'source': 'sample_pdf.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=20)\n",
    "documents=text_splitter.split_documents(text_documents)\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chroma Vector Embeddings\n",
    "\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db=Chroma.from_documents(documents,OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ence on , pp. 8595–8598. IEEE, 2013.\\nLeCun, Yann, Bottou, L ´eon, Bengio, Yoshua, and Haffner,\\nPatrick. Gradient-based learning applied to document\\nrecognition. Proceedings of the IEEE , 86(11):2278–\\n2324, 1998.\\nLewis, David D, Yang, Yiming, Rose, Tony G, and Li, Fan.\\nRcv1: A new benchmark collection for text categoriza-\\ntion research. JMLR , 2004.\\nLi, Tao, Ma, Sheng, and Ogihara, Mitsunori. Entropy-\\nbased criterion in categorical clustering. In ICML , 2004.\\nLiu, Huan and Yu, Lei. Toward integrating feature selection\\nalgorithms for classiﬁcation and clustering. IEEE Trans-\\nactions on Knowledge and Data Engineering , 2005.\\nLong, Jonathan, Shelhamer, Evan, and Darrell, Trevor.\\nFully convolutional networks for semantic segmentation.\\narXiv preprint arXiv:1411.4038 , 2014.\\nMacQueen, James et al. Some methods for classiﬁcation\\nand analysis of multivariate observations. In Proceed-\\nings of the ﬁfth Berkeley symposium on mathematical\\nstatistics and probability , pp. 281–297, 1967.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vector Database Querying\n",
    "\n",
    "query=\"What is this paper about?\"\n",
    "result = db.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FAISS Vector Database\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db1=FAISS.from_documents(documents,OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'international conference on Information and knowledge\\nmanagement , 2000.\\nSrivastava, Nitish, Hinton, Geoffrey, Krizhevsky, Alex,\\nSutskever, Ilya, and Salakhutdinov, Ruslan. Dropout: A\\nsimple way to prevent neural networks from overﬁtting.\\nJMLR , 2014.\\nSteinbach, Michael, Ert ¨oz, Levent, and Kumar, Vipin. The\\nchallenges of clustering high dimensional data. In New\\nDirections in Statistical Physics , pp. 273–309. Springer,\\n2004.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vector Database Querying\n",
    "\n",
    "query=\"What is this paper about?\"\n",
    "result = db1.similarity_search(query)\n",
    "result[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
